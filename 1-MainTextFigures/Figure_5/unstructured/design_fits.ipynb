{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525cfd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "#%qtconsole\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8853ba23",
   "metadata": {},
   "source": [
    "# Read all simulation results, train parameter scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcc35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='./../../../DataAndScripts/unstructured_scripts/simulation_results/'\n",
    "results=np.loadtxt(folder+'results_0.txt');\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_1.txt')));\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_2.txt')));\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_3.txt')));\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_4.txt')));\n",
    "sim_param_all=results[:,0:15]\n",
    "moments_of_r_sim_all=results[:,15:20]\n",
    "sim_convergence_all=results[:,20:24]\n",
    "sim_decay_all=results[:,26]/results[:,27]\n",
    "\n",
    "sim_g_E=(sim_param_all[:,2])\n",
    "sim_g_I=(sim_param_all[:,3])\n",
    "sim_beta=(sim_param_all[:,4])\n",
    "sim_CV_K=(sim_param_all[:,7])\n",
    "sim_sigma_Lambda_over_Lambda=(sim_param_all[:,10])\n",
    "sim_J=(sim_param_all[:,11])\n",
    "sim_r_X=(sim_param_all[:,12])\n",
    "sim_ell=(sim_param_all[:,13])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X=np.vstack((sim_g_E,sim_g_I,sim_beta,sim_CV_K,sim_sigma_Lambda_over_Lambda,\n",
    "             sim_J,sim_r_X,sim_ell)).T\n",
    "X[:,2::]=np.log10(X[:,2::])\n",
    "\n",
    "Y=np.zeros(np.shape(moments_of_r_sim_all))\n",
    "Y[:,:]=moments_of_r_sim_all[:,:]\n",
    "Y[:,4]=np.sign(Y[:,4])*np.sqrt(np.abs(Y[:,4]))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, random_state=123)\n",
    "\n",
    "# center training dataset\n",
    "scaler.fit(X_train) \n",
    "\n",
    "with open('scaler.pkl','wb') as f:\n",
    "    pickle.dump(scaler,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9845aec9",
   "metadata": {},
   "source": [
    "# Design fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2c403",
   "metadata": {},
   "source": [
    "## Write simulation parameters with set J and CVopto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b8e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "Possible_idx_species=[0,1]\n",
    "Possible_log10_CVopto=np.linspace(-1,1,20)\n",
    "Possible_log10_J=np.linspace(-5,-2.5,20)\n",
    "nRep=101\n",
    "\n",
    "            \n",
    "count=0;\n",
    "for idx_species in [0,1]:\n",
    "    for idx_S in range(len(Possible_log10_CVopto)):\n",
    "        log10_CVopto=Possible_log10_CVopto[idx_S]\n",
    "        for idx_J in range(len(Possible_log10_J)):\n",
    "            log10_J=Possible_log10_J[idx_J]\n",
    "            data=np.ones((1,4));\n",
    "            data[:,0]=idx_species\n",
    "            data[:,1]=log10_CVopto\n",
    "            data[:,2]=log10_J\n",
    "            data[:,3]=nRep\n",
    "\n",
    "            if count==0:\n",
    "                DATA=data;\n",
    "            if count>0:\n",
    "                DATA=np.vstack((DATA,data));\n",
    "            count=count+1\n",
    "\n",
    "len(DATA)\n",
    "\n",
    "df = pd.DataFrame(DATA,columns=['idx_species','log10_CVopto','log10_J','nRep'])\n",
    "file_name='simulation_param_Fixed_J_and_CVopto.txt'\n",
    "df.to_csv(file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d5fbc",
   "metadata": {},
   "source": [
    "## Write simulation parameters with set J and CVopto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95491ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "Possible_idx_species=[0,1]\n",
    "possible_g_E=np.linspace(3,10,20)\n",
    "\n",
    "            \n",
    "count=0;\n",
    "for idx_species in [0,1]:\n",
    "    for idx_g_E in range(len(possible_g_E)):\n",
    "        g_E=possible_g_E[idx_g_E];\n",
    "        possible_g_I=np.arange(2,g_E,np.diff(possible_g_E)[0])\n",
    "        for idx_g_I in range(len(possible_g_I)):\n",
    "            g_I=possible_g_I[idx_g_I];\n",
    "\n",
    "            data=np.ones((1,4));\n",
    "            data[:,0]=idx_species\n",
    "            data[:,1]=g_E\n",
    "            data[:,2]=g_I\n",
    "            data[:,3]=nRep\n",
    "\n",
    "            if count==0:\n",
    "                DATA=data;\n",
    "            if count>0:\n",
    "                DATA=np.vstack((DATA,data));\n",
    "            count=count+1\n",
    "\n",
    "print(len(DATA))\n",
    "\n",
    "df = pd.DataFrame(DATA,columns=['idx_species','g_E','g_I','nRep'])\n",
    "file_name='simulation_param_Fixed_gs.txt'\n",
    "df.to_csv(file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed8c7e0",
   "metadata": {},
   "source": [
    "# Train perceptron to predict optogenetic response statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e43282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e044d001",
   "metadata": {},
   "source": [
    "# Train perceptron to predict chaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eecede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
