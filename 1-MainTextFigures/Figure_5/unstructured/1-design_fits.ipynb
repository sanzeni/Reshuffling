{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b72e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "#%qtconsole\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044533dc",
   "metadata": {},
   "source": [
    "# Read all simulation results, train parameter scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8b08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='./../../../DataAndScripts/unstructured_scripts/simulation_results/'\n",
    "results=np.loadtxt(folder+'results_0.txt');\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_1.txt')));\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_2.txt')));\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_3.txt')));\n",
    "results=np.concatenate((results,np.loadtxt(folder+'results_4.txt')));\n",
    "sim_param_all=results[:,0:15]\n",
    "moments_of_r_sim_all=results[:,15:20]\n",
    "sim_convergence_all=results[:,20:24]\n",
    "sim_decay_all=results[:,26]/results[:,27]\n",
    "\n",
    "sim_g_E=(sim_param_all[:,2])\n",
    "sim_g_I=(sim_param_all[:,3])\n",
    "sim_beta=(sim_param_all[:,4])\n",
    "sim_CV_K=(sim_param_all[:,7])\n",
    "sim_sigma_Lambda_over_Lambda=(sim_param_all[:,10])\n",
    "sim_J=(sim_param_all[:,11])\n",
    "sim_r_X=(sim_param_all[:,12])\n",
    "sim_ell=(sim_param_all[:,13])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X=np.vstack((sim_g_E,sim_g_I,sim_beta,sim_CV_K,sim_sigma_Lambda_over_Lambda,\n",
    "             sim_J,sim_r_X,sim_ell)).T\n",
    "X[:,2::]=np.log10(X[:,2::])\n",
    "\n",
    "Y=np.zeros(np.shape(moments_of_r_sim_all))\n",
    "Y[:,:]=moments_of_r_sim_all[:,:]\n",
    "Y[:,4]=np.sign(Y[:,4])*np.sqrt(np.abs(Y[:,4]))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, random_state=123)\n",
    "\n",
    "# center training dataset\n",
    "scaler.fit(X_train) \n",
    "\n",
    "with open('model_files/scaler.pkl','wb') as f:\n",
    "    pickle.dump(scaler,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e3463",
   "metadata": {},
   "source": [
    "# Design fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c93017",
   "metadata": {},
   "source": [
    "## Write simulation parameters with set J and CVopto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1da250",
   "metadata": {},
   "outputs": [],
   "source": [
    "Possible_idx_species=[0,1]\n",
    "Possible_log10_CVopto=np.linspace(-1,1,20)\n",
    "Possible_log10_J=np.linspace(-5,-2.5,20)\n",
    "nRep=101\n",
    "\n",
    "            \n",
    "count=0;\n",
    "for idx_species in [0,1]:\n",
    "    for idx_S in range(len(Possible_log10_CVopto)):\n",
    "        log10_CVopto=Possible_log10_CVopto[idx_S]\n",
    "        for idx_J in range(len(Possible_log10_J)):\n",
    "            log10_J=Possible_log10_J[idx_J]\n",
    "            data=np.ones((1,4));\n",
    "            data[:,0]=idx_species\n",
    "            data[:,1]=log10_CVopto\n",
    "            data[:,2]=log10_J\n",
    "            data[:,3]=nRep\n",
    "\n",
    "            if count==0:\n",
    "                DATA=data;\n",
    "            if count>0:\n",
    "                DATA=np.vstack((DATA,data));\n",
    "            count=count+1\n",
    "\n",
    "len(DATA)\n",
    "\n",
    "df = pd.DataFrame(DATA,columns=['idx_species','log10_CVopto','log10_J','nRep'])\n",
    "file_name='simulation_files/simulation_param_Fixed_J_and_CVopto.txt'\n",
    "df.to_csv(file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c9de0",
   "metadata": {},
   "source": [
    "## Write simulation parameters with set J and CVopto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02a04478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "Possible_idx_species=[0,1]\n",
    "possible_g_E=np.linspace(3,10,20)\n",
    "\n",
    "            \n",
    "count=0;\n",
    "for idx_species in [0,1]:\n",
    "    for idx_g_E in range(len(possible_g_E)):\n",
    "        g_E=possible_g_E[idx_g_E];\n",
    "        possible_g_I=np.arange(2,g_E,np.diff(possible_g_E)[0])\n",
    "        for idx_g_I in range(len(possible_g_I)):\n",
    "            g_I=possible_g_I[idx_g_I];\n",
    "\n",
    "            data=np.ones((1,4));\n",
    "            data[:,0]=idx_species\n",
    "            data[:,1]=g_E\n",
    "            data[:,2]=g_I\n",
    "            data[:,3]=nRep\n",
    "\n",
    "            if count==0:\n",
    "                DATA=data;\n",
    "            if count>0:\n",
    "                DATA=np.vstack((DATA,data));\n",
    "            count=count+1\n",
    "\n",
    "print(len(DATA))\n",
    "\n",
    "df = pd.DataFrame(DATA,columns=['idx_species','g_E','g_I','nRep'])\n",
    "file_name='simulation_files/simulation_param_Fixed_gs.txt'\n",
    "df.to_csv(file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f14b08",
   "metadata": {},
   "source": [
    "# Train perceptron to predict optogenetic response statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 299.53041492\n",
      "Iteration 2, loss = 107.43174408\n"
     ]
    }
   ],
   "source": [
    "sim_param_all=results[:,0:15]\n",
    "moments_of_r_sim_all=results[:,15:20]\n",
    "sim_convergence_all=results[:,20:24]\n",
    "sim_decay_all=results[:,26]/results[:,27]\n",
    "\n",
    "sim_g_E=(sim_param_all[:,2])\n",
    "sim_g_I=(sim_param_all[:,3])\n",
    "sim_beta=(sim_param_all[:,4])\n",
    "sim_CV_K=(sim_param_all[:,7])\n",
    "sim_sigma_Lambda_over_Lambda=(sim_param_all[:,10])\n",
    "sim_J=(sim_param_all[:,11])\n",
    "sim_r_X=(sim_param_all[:,12])\n",
    "sim_ell=(sim_param_all[:,13])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X=np.vstack((sim_g_E,sim_g_I,sim_beta,sim_CV_K,sim_sigma_Lambda_over_Lambda,\n",
    "             sim_J,sim_r_X,sim_ell)).T\n",
    "X[:,2::]=np.log10(X[:,2::])\n",
    "\n",
    "Y=np.zeros(np.shape(moments_of_r_sim_all))\n",
    "Y[:,:]=moments_of_r_sim_all[:,:]\n",
    "Y[:,4]=np.sign(Y[:,4])*np.sqrt(np.abs(Y[:,4]))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, random_state=123)\n",
    "\n",
    "# center training dataset\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Use optimization in the plot reults file to find best network structure\n",
    "mlp_regressor  = MLPRegressor(random_state=123,\n",
    "                          activation='relu',\n",
    "                          hidden_layer_sizes=(100, 150, 50),verbose=True)\n",
    "mlp_regressor.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "#print(Y_preds[:5])\n",
    "#print(Y_test[:5])\n",
    "\n",
    "print('Test R^2 Score : %.3f'%mlp_regressor.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
    "print('Training R^2 Score : %.3f'%mlp_regressor.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb73b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_files/model.pkl','wb') as f:\n",
    "    pickle.dump(mlp_regressor,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246e2bca",
   "metadata": {},
   "source": [
    "# Train perceptron to predict chaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_param_all=results[:,0:15]\n",
    "moments_of_r_sim_all=results[:,15:20]\n",
    "sim_convergence_all=results[:,20:24]\n",
    "sim_decay_all=results[:,26]/results[:,27]\n",
    "\n",
    "sim_g_E=(sim_param_all[:,2])\n",
    "sim_g_I=(sim_param_all[:,3])\n",
    "sim_beta=(sim_param_all[:,4])\n",
    "sim_CV_K=(sim_param_all[:,7])\n",
    "sim_sigma_Lambda_over_Lambda=(sim_param_all[:,10])\n",
    "sim_J=(sim_param_all[:,11])\n",
    "sim_r_X=(sim_param_all[:,12])\n",
    "sim_ell=(sim_param_all[:,13])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "X=np.vstack((sim_g_E,sim_g_I,sim_beta,sim_CV_K,sim_sigma_Lambda_over_Lambda,\n",
    "             sim_J,sim_r_X,sim_ell)).T\n",
    "X[:,2::]=np.log10(X[:,2::])\n",
    "\n",
    "Y=np.zeros(np.shape(moments_of_r_sim_all))\n",
    "Y[:,:]=moments_of_r_sim_all[:,:]\n",
    "Y[:,4]=np.sign(Y[:,4])*np.sqrt(np.abs(Y[:,4]))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, random_state=123)\n",
    "\n",
    "# center training dataset\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Use optimization in the plot reults file to find best network structure\n",
    "mlp_regressor  = MLPRegressor(random_state=123,\n",
    "                          activation='relu',\n",
    "                          hidden_layer_sizes=(100, 150, 50),verbose=True)\n",
    "mlp_regressor.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "#print(Y_preds[:5])\n",
    "#print(Y_test[:5])\n",
    "\n",
    "print('Test R^2 Score : %.3f'%mlp_regressor.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models.\n",
    "print('Training R^2 Score : %.3f'%mlp_regressor.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74412ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_files/chaos_model.pkl','wb') as f:\n",
    "    pickle.dump(mlp_regressor,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd24be",
   "metadata": {},
   "source": [
    "# Next step: Run sim_Fixed_J_and_CVopto.py and sim_Fixed_gs.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
